+++
author = "Smaine Kahlouch"
title = "S√©curiser le Cloud avec `Tailscale` : Mise en ≈ìuvre d'un VPN simplifi√©e"
date = "2023-10-16"
summary = "Tailscale est une solution de **VPN** qui permet connecter des appareils ou serveurs de mani√®re s√©curis√©e. Comment en b√©n√©ficier pour acc√©der √† une infrastruture Cloud?"
featured = true
codeMaxLines = 21
usePageBundles = true
toc = true
tags = [
    "security",
    "network"
]
thumbnail= "thumbnail.png"
+++

Lorsqu'on parle de s√©curisation de l'acc√®s aux ressources Cloud, l'une des r√®gles d'or est d'√©viter les expositions directes √† Internet. La question qui se pose alors pour les Devs/Ops est : comment, par exemple, acc√©der √† une base de donn√©es, un cluster Kubernetes ou un serveur via SSH sans compromettre la s√©curit√©? </br>

Les **r√©seaux priv√©s virtuels (VPN)** offrent une r√©ponse en √©tablissant un lien s√©curis√© entre diff√©rents √©l√©ments d'un r√©seau, ind√©pendamment de leur localisation g√©ographique. De nombreuses solutions existent, allant de mod√®les en SaaS aux solutions que l'on peut h√©berger soi-m√™me, utilisant divers protocoles et √©tant soit open source, soit propri√©taires.

Parmi ces options, je souhaitais vous parler de [**Tailscale**](https://tailscale.com/). Cette solution utilise le protocole `WireGuard`, r√©put√© pour sa simplicit√© et sa performance.  Avec Tailscale, il est possible de connecter des appareils ou serveurs de mani√®re s√©curis√©e, comme s'ils √©taient sur un m√™me r√©seau local, bien qu'ils soient r√©partis √† travers le monde.

## :bullseye: Nos objectifs

* Comprendre comment fonctionne `Tailscale`
* Mise en oeuvre d'une connexion s√©curis√©e avec AWS en quelques minutes
* Interragir avec l'API d'un cluster EKS via un r√©seau priv√©
* Acc√©der √† des services h√©berg√©s sur Kubernetes en utilisant le r√©seau priv√©

<center><img src="admin_console.png" width="400" /></center>

Pour le reste de cet article il faudra √©videmment **cr√©er un compte Tailscale**. A noter que l'authentification est d√©l√©gu√©e √† des fournisseurs d'identit√© tiers (ex: Okta, Onelogin, Google ...).

Lorsque le compte est cr√©e, on a directement acc√®s √† la console de gestion ci-dessus. Elle permet notamment de lister les appareils connect√©s, de consulter les logs, de modifier la plupart des param√®tres...

## üí° Sous le capot

{{% notice info Terminologie %}}
**Mesh VPN**: Un _mesh VPN_ est un type de r√©seau VPN o√π chaque n≈ìud (c'est-√†-dire chaque appareil ou machine) est connect√© √† tous les autres n≈ìuds du r√©seau, formant ainsi un maillage. √Ä distinguer des configurations VPN traditionnelles qui sont con√ßues g√©n√©ralement "en √©toile", o√π plusieurs clients se connectent √† un serveur central.

**Zero trust**: Signifie que chaque demande d'acc√®s √† un r√©seau est trait√©e comme si elle venait d'une source non fiable. Une application ou utilisateur doit prouver son identit√© et √™tre autoris√©e avant d'acc√©der √† une ressource. On ne fait pas confiance simplement parce qu'une machine ou un utilisateur provient d'un r√©seau interne ou d'une certaine zone g√©ographique.

**Tailnet**: D√®s la premi√®re utilisation de Tailscale, un _Tailnet_ est cr√©e pour vous et correspond √† votre propre r√©seau priv√©. Chaque appareil dans un tailnet re√ßoit une IP Tailscale unique, permettant une communication directe entre eux. Chacun de ces r√©seaux poss√®de son propre nom ainsi qu'un label associ√© √† une organisation.
{{% /notice %}}

<center><img src="mesh.png" width="500" /></center>

L'architecture de Tailscale est con√ßue de telle sorte que le _Control plane_ et le _Data plane_ sont clairement s√©par√©s:

* D'une part, il y a le **serveur de coordination**. Son r√¥le est d'√©changer des m√©tadonn√©es et des cl√©s publiques entre tous les participants d'un Tailnet (La cl√© priv√©e √©tant gard√©e en toute s√©curit√© son n≈ìud d'origine).

* D'autre part, les n≈ìuds du Tailnet s'organisent en un **r√©seau maill√©** (_Mesh_). Au lieu de passer par le serveur de coordination pour √©changer des donn√©es, ces n≈ìuds communiquent directement les uns avec les autres en mode **point √† point**. Chaque n≈ìud dispose d'une identit√© unique pour s'authentifier et rejoindre le Tailnet.

## :inbox_tray: Installation du client

La majorit√© des plateformes sont support√©es et les proc√©dures d'installation sont list√©es [ici](https://tailscale.com/kb/installation/).
En ce qui me concerne je suis sur Archlinux:

```console
sudo pacman -S tailscale
```

Il est possible de d√©marrer le service automatiquement au d√©marrage de la machine.
```console
sudo systemctl enable --now tailscaled
```

Pour enregistrer son ordinateur perso, lancer la commande suivante:
```console
sudo tailscale up --accept-routes

To authenticate, visit:

        https://login.tailscale.com/a/f50...
```

<center><img src="laptop_connected.png" width="850" /></center>


‚ÑπÔ∏è l'option `--accept-routes` est n√©cessaire sur Linux et permettra d'accepter les routes annonc√©es par les Subnet routers. On verra cela dans la suite de l'article

V√©rifier que vous avez bien obtenu une IP du r√©seau Tailscale:
```console
tailscale ip -4
100.118.83.67

tailscale status
100.118.83.67   ogenki               smainklh@    linux   -
```

‚ÑπÔ∏è Pour les utilisateurs de Linux, v√©rifier que Tailscale fonctionne bien avec votre configuration DNS: Suivre [cette documentation](https://tailscale.com/kb/1188/linux-dns/).

{{% notice tip "Les sources" %}}
Toutes les √©tapes r√©alis√©es dans cet article proviennent de ce [**d√©p√¥t git**](https://github.com/Smana/demo-secured-eks)

Il va permettre de cr√©er l'ensemble des composants qui ont pour objectif d'obtenir un cluster EKS de Lab et font suite √† un pr√©c√©dent article sur [Cilium et Gateway API](https://blog.ogenki.io/fr/post/cilium-gateway-api/).

{{% /notice %}}

## ‚òÅÔ∏è Acc√©der √† AWS en priv√©

![Subnet router](subnet_router.png)

Afin de pouvoir acc√©der de mani√®re s√©curis√©e √† l'ensemble des ressources disponibles sur AWS, il est possible de d√©ployer un _**Subnet router**_.

Un _Subnet router_ est une instance Tailscale qui permet d'acc√©der √† des sous-r√©seaux qui ne sont pas directement li√©s √† Tailscale. Il fait office de **pont** entre le r√©seau priv√© virtuel de Tailscale (_Tailnet_) et d'autres r√©seaux locaux.

Nous pouvons alors **router des sous r√©seaux du Clouder √† travers le VPN de Tailscale**.

‚ö†Ô∏è Pour ce faire, sur AWS, il faudra bien entendu configurer les _security groups_ correctement pour autoriser les Subnet routers.


### üöÄ D√©ployer un Subnet router

Entrons dans le vif du sujet et deployons un _Subnet router_ sur un r√©seau AWS!</br>
Tout est fait en utilisant le code **Terraform** pr√©sent dans le r√©pertoire [terraform/network](https://github.com/Smana/demo-secured-eks/tree/main/terraform/network). Nous allons analyser la configuration sp√©cifique √† Tailscale qui est pr√©sente dans le fichier [tailscale.tf](https://github.com/Smana/demo-secured-eks/blob/main/terraform/network/tailscale.tf) avant de proc√©der au d√©ploiement.

#### Le provider Terraform

Il est possible de configurer certains param√®tres au travers de l'**API** Tailscale gr√¢ce au [provider Terraform](https://github.com/tailscale/terraform-provider-tailscale).
Pour cela il faut au pr√©alable g√©nerer une cl√© d'API üîë sur la console d'admin:

<center><img src="api_key.png" width="750" /></center>

Il faudra conserver cette cl√© dans un endroit s√©curis√© car elle est utilis√©e pour d√©ployer le Subnet router

```hcl
provider "tailscale" {
  api_key = var.tailscale.api_key
  tailnet = var.tailscale.tailnet
}
```

<ins>**les ACL's**</ins>

Les ACL's permettent de d√©finir qui est autoris√© √† communiquer avec qui (utilisateur ou appareil). √Ä la cr√©ation d'un compte, celle-cis sont tr√®s permissives et il n'y a aucune restriction (tout le monde peut parler avec tout le monde).

```hcl
resource "tailscale_acl" "this" {
  acl = jsonencode({
    acls = [
      {
        action = "accept"
        src    = ["*"]
        dst    = ["*:*"]
      }
    ]
...
}
```
{{% notice note Note %}}
Pour mon environnement de Lab, j'ai conserv√© cette configuration par d√©fault car je suis la seule personne √† y acc√©der. De plus les seuls appareils connect√©s √† mon Tailnet sont mon laptop et le Subnet router. En revanche dans un cadre d'entreprise, il faudra bien y r√©fl√©chir. Il est alors possible de d√©finir une politique bas√©e sur des groupes d'utilisitateurs ou sur les tags des noeuds.

Consulter cette [doc](https://tailscale.com/kb/1018/acls/) pour plus d'info.
{{% /notice %}}

<ins>**Les noms de domaines (DNS)**</ins>

Il y a [diff√©rentes fa√ßons](https://tailscale.com/kb/1054/dns/) possibles de g√©rer les noms de domaines avec Tailscale:

**Magic DNS**: Lorsqu'un appareil rejoint le Tailnet, il s'enregistre avec un nom et celui-ci peut-√™tre utilis√© directement pour communiquer avec l'appareil.
```console
tailscale status
100.118.83.67   ogenki               smainklh@    linux   -
100.115.31.152  ip-10-0-43-98        smainklh@    linux   active; relay "par", tx 3044 rx 2588

ping ip-10-0-43-98
PING ip-10-0-43-98.tail9c382.ts.net (100.115.31.152) 56(84) bytes of data.
64 bytes from ip-10-0-43-98.tail9c382.ts.net (100.115.31.152): icmp_seq=1 ttl=64 time=11.4 ms
```

**AWS**: Pour utiliser les noms de domaines internes √† AWS il est possible d'utiliser la [deuxi√®me IP du VPC](https://docs.aws.amazon.com/vpc/latest/userguide/vpc-dns.html#AmazonDNS) qui correspond toujours au serveur DNS. Cela permet d'utiliser les √©ventuelles zones priv√©es sur route53 ou de se connecter aux ressources en utilisant les noms de domaines.

La configuration la plus simple est donc de d√©clarer la liste des serveurs DNS √† utiliser et d'y ajouter celui de AWS. Ici un exemple avec le DNS publique de Cloudflare.

```hcl
resource "tailscale_dns_nameservers" "this" {
  nameservers = [
    "1.1.1.1",
    cidrhost(module.vpc.vpc_cidr_block, 2)
  ]
}
```

<ins>**La cl√© d'authentification ("auth key")**</ins>

Pour qu'un appareil puisse rejoindre le Tailnet au d√©marrage il faut que Tailscale soit d√©marr√© en utilisant une cl√© d'authentification. Celle-ci est g√©n√©r√©e comme suit

```hcl
resource "tailscale_tailnet_key" "this" {
  reusable      = true
  ephemeral     = false
  preauthorized = true
}
```

* `reusable`: S'agissant d'un `autoscaling group`, il faut que cette m√™me cl√© puisse √™tre utilis√©e plusieurs fois.
* `ephemeral`: Pour cette d√©mo nous cr√©ons une cl√© qui n'expire pas. En production il serait pr√©f√©rable d'activer l'expiration.
* `preauthorized`: Il faut que cette cl√© soit d√©j√† valide et autoris√©e pour que l'instance rejoigne automatiquement le Tailscale.

La cl√© ainsi g√©n√©r√©e est utilis√©e pour lancer tailscale avec le param√®tre `--auth-key`
```console
sudo tailscale up --authkey=<REDACTED>
```


<ins>**Annoncer les routes pour les r√©seaux AWS**</ins>

Enfin il faut annoncer le r√©seau que l'on souhaite faire passer par le _Subnet router_. Dans notre exemple, nous d√©cidons de router tout le r√©seau du VPC qui a pour CIDR `10.0.0.0/16`.

Afin que cela soit possible de fa√ßon automatique, il y a une r√®gle [autoApprovers](https://tailscale.com/kb/1018/acls/#auto-approvers-for-routes-and-exit-nodes) √† ajouter. Cela permet d'indiquer que les routes annonc√©es par l'utilisateur `smainklh@gmail.com` sont autoris√©es sans que cela requiert une √©tape d'approbation.

```hcl
    autoApprovers = {
      routes = {
        "10.0.0.0/16" = ["smainklh@gmail.com"]
      }
    }
```

La commande lanc√©e au d√©marrage de l'instance _Subnet router_ est la suivante:
```console
sudo tailscale up --authkey=<REDACTED> --advertise-routes="10.0.0.0/16"
```

#### Le module Terraform

J'ai cr√©√© un [module](https://github.com/Smana/terraform-aws-tailscale-subnet-router) tr√®s simple qui permet de d√©ployer un `autoscaling group` sur AWS et de configurer Tailscale. Au d√©marrage de l'instance, elle s'authentifiera en utilisant une `auth_key` et annoncera les r√©seaux indiqu√©s. Dans l'exemple ci-dessous l'instance annonce le CIDR du VPC sur AWS.

```hcl
module "tailscale_subnet_router" {
  source  = "Smana/tailscale-subnet-router/aws"
  version = "1.0.4"

  region = var.region
  env    = var.env

  name     = var.tailscale.subnet_router_name
  auth_key = tailscale_tailnet_key.this.key

  vpc_id                = module.vpc.vpc_id
  subnet_ids            = module.vpc.private_subnets
  advertise_routes      = [module.vpc.vpc_cidr_block]
...
}
```

Maintenant que nous avons analys√© les diff√©rents param√®tres, il est temps de **d√©marrer notre Subnet router** üöÄ !! </br>

Il faut au pr√©alable cr√©er un fichier `variable.tfvars` dans le r√©pertoire [terraform/network](https://github.com/Smana/demo-secured-eks/tree/main/terraform/network).

```hcl
env                 = "dev"
region              = "eu-west-3"
private_domain_name = "priv.cloud.ogenki.io"

tailscale = {
  subnet_router_name = "ogenki"
  tailnet            = "smainklh@gmail.com"
  api_key            = "tskey-api-..."
}

tags = {
  project = "demo-secured-eks"
  owner   = "Smana"
}
```


Puis lancer la commande suivante:
```console
tofu plan --var-file variables.tfvars
```

Apr√®s v√©rification du plan, appliquer les changements

```console
tofu apply --var-file variables.tfvars
```

Quand l'instance est d√©marr√©e, elle apparaitra dans la liste des appareils du Tailnet.
```console
tailscale status
100.118.83.67   ogenki               smainklh@    linux   -
100.68.109.138  ip-10-0-26-99        smainklh@    linux   active; relay "par", tx 33868 rx 32292
```

Nous pouvons aussi v√©rifier que la route est bien annonc√©e comme suit:
```console
tailscale status --json|jq '.Peer[] | select(.HostName == "ip-10-0-26-99") .PrimaryRoutes'
[
  "10.0.0.0/16"
]
```

‚ö†Ô∏è Pour des raisons de s√©curit√©, pensez √† supprimer le fichier `variables.tfvars` car il contient la cl√© d'API.

üëè Et voil√† ! Nous sommes maintenant en mesure d'**acc√©der au r√©seau sur AWS**, √† condition d'avoir √©galement configur√© les r√®gles de filtrage, comme les ACL et les security groups. Nous pouvons par exemple acc√©der √† une base de donn√©es depuis le poste de travail

```console
psql -h demo-tailscale.cymnaynfchjt.eu-west-3.rds.amazonaws.com -U postgres
Password for user postgres:
psql (15.4, server 15.3)
SSL connection (protocol: TLSv1.2, cipher: ECDHE-RSA-AES256-GCM-SHA384, compression: off)
Type "help" for help.

postgres=>
```

### üíª Une autre fa√ßon de faire du SSH

Traditionnellement, nous devons parfois nous connecter √† des serveurs en utilisant le protocole SSH. Pour ce faire, il faut g√©n√©rer une cl√© priv√©e et distribuer la cl√© publique correspondante sur les serveurs distants.

Contrairement √† l'utilisation des cl√©s SSH classiques, √©tant donn√© que Tailscale utilise `Wireguard` pour l'authentification et le chiffrement des connexions il n'est **pas n√©cessaire de r√©-authentifier le client**. De plus, Tailscale g√®re √©galement la distribution des cl√©s SSH d'h√¥tes. Les r√®gles ACL permettent de r√©voquer l'acc√®s des utilisateurs sans avoir √† supprimer les cl√©s SSH. De plus, il est possible d'activer un mode de v√©rification qui renforce la s√©curit√© en exigeant une r√©-authentification p√©riodique. On peut donc affirmer que l'utilisation de `Tailscale SSH` **simplifie** l'authentification, la gestion des connexions SSH et **am√©liore le niveau de s√©curit√©**.

Les autorisations pour utiliser SSH sont aussi g√©r√©es au niveau des ACL's
```hcl
...
    ssh = [
      {
        action = "check"
        src    = ["autogroup:member"]
        dst    = ["autogroup:self"]
        users  = ["autogroup:nonroot"]
      }
    ]
...
```

La r√®gle ci-dessus autorise tous les utilisateurs √† acc√©der √† leurs propres appareils en utilisant SSH. Lorsqu'ils essaient de se connecter, ils doivent utiliser un compte utilisateur autre que `root`.
Pour chaque tentative de connexion, une authentification suppl√©mentaire est n√©cessaire (`action=check`). Cette authentification se fait en visitant un lien web sp√©cifique

```console
ssh ubuntu@ip-10-0-26-99
...
# Tailscale SSH requires an additional check.
# To authenticate, visit: https://login.tailscale.com/a/f1f09a548cc6
...
ubuntu@ip-10-0-26-99:~$
```

Pour que cela soit possible il faut aussi d√©marrer Tailscale avec l'option `--ssh`

Les logs d'acc√®s √† la machine peuvent √™tre consult√©s en utilisant `journalctl`
```console
ubuntu@ip-10-0-26-99:~$ journalctl -aeu tailscaled|grep ssh
Oct 15 15:51:34 ip-10-0-26-99 tailscaled[1768]: ssh-conn-20231015T155130-00ede660b8: handling conn: 100.118.83.67:55098->ubuntu@100.68.109.138:22
Oct 15 15:51:56 ip-10-0-26-99 tailscaled[1768]: ssh-conn-20231015T155156-b6d1dc28c0: handling conn: 100.118.83.67:44560->ubuntu@100.68.109.138:22
Oct 15 15:52:52 ip-10-0-26-99 tailscaled[1768]: ssh-conn-20231015T155156-b6d1dc28c0: starting session: sess-20231015T155252-5b2acc170e
Oct 15 15:52:52 ip-10-0-26-99 tailscaled[1768]: ssh-session(sess-20231015T155252-5b2acc170e): handling new SSH connection from smainklh@gmail.com (100.118.83.67) to ssh-user "ubuntu"
Oct 15 15:52:52 ip-10-0-26-99 tailscaled[1768]: ssh-session(sess-20231015T155252-5b2acc170e): access granted to smainklh@gmail.com as ssh-user "ubuntu"
Oct 15 15:52:52 ip-10-0-26-99 tailscaled[1768]: ssh-session(sess-20231015T155252-5b2acc170e): starting pty command: [/usr/sbin/tailscaled be-child ssh --uid=1000 --gid=1000 --groups=1000,4,20,24,25,27,29,30,44,46,115,116 --local-user=ubuntu --remote-user=smainklh@gmail.com --remote-ip=100.118.83.67 --has-tty=true --tty-name=pts/0 --shell --login-cmd=/usr/bin/login --cmd=/bin/bash -- -l]
```

‚ÑπÔ∏è Avec Tailscale SSH il est possible de se connecter en SSH peu importe o√π est situ√© l'appareil. En revanche dans un contexte 100% AWS, on pr√©ferera probablement utiliser [AWS SSM](https://docs.aws.amazon.com/systems-manager/latest/userguide/session-manager.html).

{{% notice info Logs %}}
üíæ En s√©curit√© il est primordial de pouvoir conserver les logs pour un usage ult√©rieur. Il existe diff√©rents types de logs:

**Logs d'audit**: Ils sont essentiels pour savoir qui a fait quoi. Ils sont accessibles sur la console d'admin et peuvent aussi √™tre envoy√©s vers un [SIEM](https://tailscale.com/learn/security-information-and-event-management/).

**Logs sur les appareils**: Ceux-cis peuvent √™tre consult√©s en utilisant les commandes appropri√©es √† l'appareil. (`journalctl -u tailscaled` sur Linux)

**Logs r√©seau**: Utiles pour visualiser quels appareils sont connect√©s les uns aux autres.

{{% /notice %}}

### ‚ò∏ Qu'en est-il de Kubernetes?

Sur Kubernetes il existe [plusieurs options](https://tailscale.com/kb/1185/kubernetes/) pour acc√©der √† un `Service`:

* **Proxy**: Il s'agit d'un pod suppl√©mentaire qui transfert les appels √† un Service existant.
* **Sidecar**: Permet de connecter le pod au Tailnet. Donc la connectivit√© se fait de bout en bout et il est m√™me possible de communiquer dans les 2 sens. (du pod vers les noeuds du Tailnet).
* **Operator**: Permet d'exposer les services et l'API Kubernetes (`ingress`) ainsi que de permettre aux pods d'acc√©der aux noeuds du Tailnet (`egress`). La configuration se fait en configurant les ressources existantes: Services et Ingresses

Dans notre cas, nous disposons d√©j√† d'un _Subnet router_ qui route tout le r√©seau du VPC. Il suffit donc que notre service soit expos√© sur une IP priv√©e.

#### L'API Kubernetes

Pour acc√©der √† l'API Kubernetes il est n√©cessaire d'**autoriser le Subnet router**. Cela se fait en d√©finissant la r√®gle suivante pour le _security group_ source.

```hcl
module "eks" {
...
  cluster_security_group_additional_rules = {
    ingress_source_security_group_id = {
      description              = "Ingress from the Tailscale security group to the API server"
      protocol                 = "tcp"
      from_port                = 443
      to_port                  = 443
      type                     = "ingress"
      source_security_group_id = data.aws_security_group.tailscale.id
    }
  }
...
}
```

Nous allons v√©rifier que l'API est bien accessible sur une IP priv√©e.

```console
CLUSTER_URL=$(TERM=dumb kubectl cluster-info | grep "Kubernetes control plane" | awk '{print $NF}')

curl -s -o /dev/null -w '%{remote_ip}\n' ${CLUSTER_URL}
10.228.244.167

kubectl get ns
NAME                STATUS   AGE
cilium-secrets      Active   5m46s
crossplane-system   Active   4m1s
default             Active   23m
flux-system         Active   5m29s
infrastructure      Active   4m1s
...
```

#### Acc√©der aux services en priv√©

Un `Service` Kubernetes expos√© est une resource AWS comme une autre üòâ. Il faut juste s'assurer que ce service utilise bien une **IP priv√©e**.
Dans mon exemple j'utilise `Gateway API` pour configurer la r√©partition de charge du Clouder et je vous invite √† lire mon [**pr√©c√©dent article**](https://blog.ogenki.io/fr/post/cilium-gateway-api/) sur le sujet.

Il suffirait donc  de cr√©er un NLB interne en s'assurant que le `Service` ait bien l'annotation `service.beta.kubernetes.io/aws-load-balancer-scheme` ayant pour valeur `internal`. Dans le cas de Gateway API, cela se fait via la [clusterPolicy](https://github.com/Smana/demo-secured-eks/blob/main/security/mycluster-0/platform-gw-clusterpolicy.yaml) [Kyverno](https://kyverno.io/).

```yaml
          metadata:
            annotations:
              external-dns.alpha.kubernetes.io/hostname: gitops-${cluster_name}.priv.${domain_name},grafana-${cluster_name}.priv.${domain_name}
              service.beta.kubernetes.io/aws-load-balancer-scheme: "internal"
              service.beta.kubernetes.io/aws-load-balancer-backend-protocol: tcp
          spec:
            loadBalancerClass: service.k8s.aws/nlb
```

Il y a cependant un pr√©requis suppl√©mentaire car nous ne pouvons pas utiliser Let's Encrypt pour les certificats internes. J'ai donc g√©n√©r√© une **PKI interne** qui g√©n√®re des certificates auto-sign√©s avec [Cert-manager](https://cert-manager.io/).

Ici je ne d√©taillerai pas le d√©ploiement du cluster EKS, ni la configuration de [Flux](https://fluxcd.io/). Lorsque le cluster est cr√©√© et que toutes les ressources Kubernetes ont √©t√© r√©concili√©, nous avons un service qui est expos√© via un LoadBalancer interne AWS.

```console
NLB_DOMAIN=$(kubectl get svc -n infrastructure cilium-gateway-platform -o jsonpath={.status.loadBalancer.ingress[0].hostname})
dig +short ${NLB_DOMAIN}
10.0.33.5
10.0.26.228
10.0.9.183
```

Une entr√©e DNS est √©galement cr√©√©e automatiquement pour les services expos√©s et nous pouvons donc acc√©der en priv√© gr√¢ce √† Tailscale.
```console
dig +short gitops-mycluster-0.priv.cloud.ogenki.io
10.0.9.183
10.0.26.228
10.0.33.5
```

<center><img src="gitops-login.png" width="750" /></center>


## üí≠ Derni√®res remarques

Il y a quelques temps, dans le cadre professionnel, j'ai mis en place [Cloudflare Zero Trust](https://developers.cloudflare.com/cloudflare-one/). Je d√©couvre ici que Tailscale pr√©sente de nombreuses similitudes avec cette solution. La d√©cision entre les deux est loin d'√™tre triviale et d√©pend grandement du contexte. Pour ma part, j'ai √©t√© particuli√®rement **convaincu par la simplicit√© de mise en ≈ìuvre** de Tailscale, r√©pondant parfaitement √† mon besoin d'acc√©der au r√©seau du Clouder. Bien entendu il existe d'autres solutions comme [Teleport](https://goteleport.com/), qui offre une approche diff√©rente pour acc√©der √† des ressources internes.

Cela dit, focalisons-nous sur `Tailscale`.

Une partie du code de Tailscale est **open source**, notamment le client qui est sous license [BSD 3-Clause](https://opensource.org/license/bsd-3-clause/). La partie propri√©taire concerne √©ssentiellement la plateforme de coordination.   √Ä noter qu'il existe une alternative open source nomm√©e [Headscale](https://github.com/juanfont/headscale). Celle-ci est une initiative distincte qui n'a aucun lien avec la soci√©t√© `Tailscale`.

Pour un usage **personnel**, Tailscale est vraiment g√©n√©reux, offrant un acc√®s gratuit pour jusqu'√† **100 appareils et 3 utilisateurs**. Ceci-dit Tailscale est une option s√©rieuse √† consid√©rer en entreprise et il est important, selon moi, d'encourager ce type d'entreprises qui ont une politique open source claire et un produit de qualit√©.
