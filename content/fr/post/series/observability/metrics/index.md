+++
author = "Smaine Kahlouch"
title = "Une solution compl√®te et performante pour g√©rer vos m√©triques avec les op√©rateurs `VictoriaMetrics` et `Grafana`!"
date = "2024-09-11"
summary = "Il existe une multitude de solutions pour **collecter, stocker et visualiser des m√©triques**. La combinaison la plus courante repose souvent sur Prometheus et Grafana. Dans cet article, nous allons aller plus loin üöÄ en explorant une solution optimis√©e, performante et scalable bas√©e sur VictoriaMetrics."
featured = true
codeMaxLines = 30
usePageBundles = true
toc = true
series = [
  "observability"
]
tags = [
    "observability"
]
thumbnail= "thumbnail.png"
+++

{{% notice info "Comment se portent nos applications? üëÅÔ∏è" %}}
Une fois que notre application est d√©ploy√©e, il est primordial de disposer d'indicateurs permettant d'identifier d'√©ventuels probl√®mes ainsi que suivre les √©volutions de performance. Parmi ces √©l√©ments, les **m√©triques** et les **logs** jouent un r√¥le essentiel en fournissant des informations pr√©cieuses sur le fonctionnement de l'application. En compl√©ment, il est souvent utile de mettre en place un **tracing** d√©taill√© pour suivre pr√©cis√©ment toutes les actions r√©alis√©es par l'application.

Dans cette [s√©rie d'articles](http://localhost:1313/fr/series/observability/), nous allons explorer les diff√©rents aspects li√©s √† la supervision applicative. L'objectif √©tant d'analyser en d√©tail l'√©tat de nos applications, afin d'am√©liorer leur **disponibilit√©** et leurs **performances**, tout en garantissant une exp√©rience utilisateur optimale.
{{% /notice %}}

Ce premier volet est consacr√© √† **la collecte et la visualisation des m√©triques**. Nous allons d√©ployer une solution performante et √©volutive pour acheminer ces m√©triques vers un syst√®me de **stockage fiable et p√©renne**. Puis nous allons voir comment les **visualiser** afin de les analyser.

## ‚ùì Qu'est ce qu'une m√©trique


### Definition

Avant de collecter cette dite "m√©trique", penchons-nous d'abord sur sa d√©finition et ses sp√©cificit√©s: </br>
Une m√©trique est une donn√©e **mesurable** qui permet de suivre l'√©tat et les performances d'une application. Ces donn√©es sont g√©n√©ralement des chiffres collect√©s √† **intervals r√©guliers**, on peut citer par exemple le nombre de requ√™tes, la quantit√© de m√©moire ou le taux d'erreurs.

Et quand on s'int√©resse au domaine de la supervision, il est difficile de passer √† cot√© de [Prometheus](https://prometheus.io/). Ce projet a notamment permis le l'√©mergence d'un **standard** qui d√©finit la mani√®re dont on expose des m√©triques appel√© [**OpenMetrics**](https://github.com/OpenObservability/OpenMetrics/blob/main/specification/OpenMetrics.md) dont voici le format.

<center><img src="raw-sample.png" width=700 alt=""></center>

* **Time Series**: Une `time series` unique est la combinaison du nom de la m√©trique ainsi que ses labels, par cons√©quent `request_total{code="200"}` et `request_total{code="500"}` sont bien 2 _time series_ distinctes.

* **Labels**: On peut associer des `labels` √† une m√©trique afin de la caract√©riser plus pr√©cis√©ment. Ils sont ajout√©es √† la suite du nom de la m√©trique en utilisant des accolades. Bien qu'ils soient optionnels, nous les retrouverons tr√®s souvent, notamment dans sur un cluster Kubernetes (pod, namespace...).

* **Value**: La `value` repr√©sente une donn√©e num√©rique recueillie √† un moment donn√© pour une time series sp√©cifique. Selon le [**type de m√©trique**](https://prometheus.io/docs/concepts/metric_types/), il s'agit d'une valeur qui peut √™tre mesur√©e ou compt√©e afin de suivre l'√©volution d'un indicateur dans le temps.

* **Timestamp**: Indique **quand** la donn√©e a √©t√© collect√©e (format epoch √† la milliseconde)

Cette ligne compl√®te repr√©sente ce que l'on appelle un `raw sample`.

{{% notice note "Attention √† la cardinalit√©!" %}}
Plus il y a de labels, plus les combinaisons possibles augmentent, et par cons√©quent, le nombre de timeseries. Le nombre total de combinaisons est appel√© **cardinalit√©**. Une cardinalit√© √©lev√©e peut avoir un **impact significatif sur les performances**, notamment en termes de consommation de m√©moire et de ressources de stockage.

Une cardinalit√© √©lev√©e se produit √©galement lorsque de nouvelles m√©triques sont cr√©√©es fr√©quemment. Ce ph√©nom√®ne, appel√© **churn rate**, indique le rythme auquel des m√©triques apparaissent puis disparaissent dans un syst√®me. Dans le contexte de Kubernetes, o√π des pods sont r√©guli√®rement cr√©√©s et supprim√©s, ce churn rate peut contribuer √† l'augmentation rapide de la cardinalit√©.
{{% /notice %}}

### La collecte en bref

Maintenant que l'on sait ce qu'est une m√©trique, voyons comment elles sont collect√©es. La plupart des solutions modernes exposent un endpoint qui permet de **"scraper" les m√©triques**, c'est-√†-dire de les interroger **√† intervalle r√©gulier**. Par exemple, gr√¢ce au SDK Prometheus, disponible dans la plupart des langages de programmation, il est facile d'int√©grer cette collecte dans nos applications.

Il est d'ailleurs important de souligner que Prometheus utilise, en r√®gle g√©n√©rale, un mod√®le de collecte en mode "**Pull**", o√π le serveur interroge p√©riodiquement les services pour r√©cup√©rer les m√©triques via ces endpoints expos√©s. Cette approche permet de mieux contr√¥ler la fr√©quence de collecte des donn√©es et d'√©viter de surcharger les syst√®mes. On distinguera donc le mode "**Push**" o√π ce sont les applications qui envoient directement les informations.

Illustrons cela concr√®tement avec un serveur web Nginx. Ce serveur est install√© √† partir du chart Helm en activant le support de Prometheus. Ici le param√®tre `metrics.enabled=true` permet d'ajouter un chemin qui expose les m√©triques.

```console
helm install ogenki-nginx bitnami/nginx --set metrics.enabled=true
```

Ainsi, nous pouvons par exemple r√©cup√©rer via un simple appel http un nombre de m√©triques important
```console
kubectl port-forward svc/ogenki-nginx metrics &
Forwarding from 127.0.0.1:9113 -> 9113

curl -s localhost:9113/metrics
...
# TYPE promhttp_metric_handler_requests_total counter
promhttp_metric_handler_requests_total{code="200"} 257
...
```

La commande curl √©tait juste un exemple, La collecte est, en effet r√©alis√©e par un syst√®me dont la responsabilit√© est de **stoquer ces donn√©es** pour pouvoir ensuite les exploiter et les analyser. </br>
Dans cet article, j'ai choisi de vous faire d√©couvrir `VictoriaMetrics`.

## ‚ú® VictoriaMetrics: Un h√©ritier de Prometheus

Tout comme Prometheus, VictoriaMetrics est une **base de donn√©es Time Series** ([TSDB](https://en.wikipedia.org/wiki/Time_series_database)). Celles-cis sont con√ßues pour suivre et stocker des √©v√©nements qui **√©voluent au fil du temps**. M√™me si VictoriaMetrics est apparue quelques ann√©es apr√®s Prometheus, elles partagent pas mal de points communs : ce sont toutes deux des bases de donn√©es **open-source** sous licence Apache 2.0, d√©di√©es au traitement des time series. VictoriaMetrics reste enti√®rement compatible avec Prometheus, en utilisant le m√™me format de m√©triques, `OpenMetrics`, et un support total du langage de requ√™tes `PromQL`.

Ces deux projets sont d‚Äôailleurs tr√®s actifs, avec des communaut√©s dynamiques et des contributions r√©guli√®res venant de nombreuses entreprises [comme on peut le voir ici](https://ossinsight.io/analyze/prometheus/prometheus?vs=VictoriaMetrics%2FVictoriaMetrics#overview).

Explorons maintenant les principales diff√©rences et les raisons qui pourraient pousser √† choisir VictoriaMetrics :

* **Stockage et compression efficace** : C'est probablement l'un des arguments majeurs, surtout quand on g√®re un volume important de donn√©es ou qu'on souhaite les conserver √† long terme. Avec Prometheus, il faut ajouter un composant suppl√©mentaire, comme [Thanos](https://thanos.io/), pour cela. VictoriaMetrics, en revanche, dispose d'un **moteur de stockage optimis√©** qui regroupe et optimise les donn√©es avant de les √©crire sur disque. De plus, il utilise des **algorithmes de compression tr√®s puissants**, offrant une utilisation de l'espace disque bien plus efficace que Prometheus.

* **Empreinte m√©moire** : VictoriaMetrics consommerait jusqu'√† 7 fois moins de m√©moire qu'une solution bas√©e sur Prometheus. Cela dit, les benchmarks disponibles en ligne commencent √† dater, et Prometheus a b√©n√©fici√© de [nombreuses optimisations de m√©moire](https://thenewstack.io/30-pull-requests-later-prometheus-memory-use-is-cut-in-half/).

* **MetricsQL** : VictoriaMetrics √©tend le langage PromQL avec de nouvelles fonctions. Ce language est aussi con√ßu pour √™tre plus performant, notamment sur un large dataset.

* **Architecture modulaire**: VictoriaMetrics peut √™tre d√©ploy√© en 2 modes: "Single" ou "Cluster". Selon le besoin on pourra aller bien plus loin: On verra cela dans la suite de l'article.

* **Et bien d'autres...**: Les arguments ci-dessus sont ceux que j'ai retenu mais il y en a d'autres. VictoriaMetrics peut aussi √™tre utilis√© en mode **Push**, configur√© pour du **multitenant** et d'autres fonctions que l'on retrouvera dans la [**version entreprise**](https://docs.victoriametrics.com/enterprise/#victoriametrics-enterprise-features).

{{% notice info "Case studies: ce qu'ils en disent" %}}
Sur le site de VictoriaMetrics, on trouve de nombreux [t√©moignages et retours d'exp√©rience](https://docs.victoriametrics.com/casestudies/) d'entreprises ayant migr√© depuis d'autres syst√®mes (comme Thanos, InfluxDB, etc.). Certains exemples sont particuli√®rement instructifs, notamment ceux de [Roblox](https://www.datanami.com/2023/05/30/why-roblox-picked-victoriametrics-for-observability-data-overhaul/), [Razorpay](https://engineering.razorpay.com/scaling-to-trillions-of-metric-data-points-f569a5b654f2) ou [Criteo](https://techblog.criteo.com/victoriametrics-a-prometheus-remote-storage-solution-57081a3d8e61), qui g√®rent un volume tr√®s important de m√©triques.
{{% /notice %}}


## üîé Une architecture modulaire et scalable

{{% notice tip "D√©ploiement: GitOps et Op√©rateurs Kubernetes" %}}
<table>
  <tr>
        <td>
          <img src="repo_gift.png" style="width:80%;">
        </td>
        <td style="vertical-align:middle; padding-left:10px;" width="70%">

Le reste de cet article est issu d'un ensemble de configurations que vous pouvez retrouver dans le repository <strong><a href="https://github.com/Smana/demo-cloud-native-ref">Cloud Native Ref</a></strong>.</br>
Il y est fait usage de nombreux op√©rateurs et notamment ceux pour [VictoriaMetrics](https://github.com/VictoriaMetrics/operator) et pour [Grafana](https://github.com/grafana/grafana-operator).

L'ambition de ce projet est de pouvoir <strong>d√©marrer rapidement une plateforme compl√®te</strong> qui applique les bonnes pratiques en terme d'automatisation, de supervision, de s√©curit√© etc. </br>
Les commentaires et contributions sont les bienvenues üôè
        </td>
  </tr>
</table>
{{% /notice %}}

`VictoriaMetrics` peut √™tre d√©ploy√© de diff√©rentes mani√®res: Le mode par d√©faut est appel√© `Single` et, comme son nom l'indique, il s'agit de d√©ployer une **instance unique** qui g√®re la lecture, l'√©criture et le stockage. Il est d'ailleurs recommand√© de commencer par celui-ci car il est **optimis√©** et r√©pond √† la plupart des cas d'usage comme le pr√©cise [ce paragraphe](https://docs.victoriametrics.com/#capacity-planning).

### Le mode Single

La m√©thode de d√©ploiement choisie dans cet article fait usage du chart Helm [**victoria-metrics-k8s-stack**](https://github.com/VictoriaMetrics/helm-charts/tree/master/charts/victoria-metrics-k8s-stack). Voici un exemple de configuration [Flux](https://fluxcd.io/) pour un mode `Single`

[observability/base/victoria-metrics-k8s-stack/helmrelease-vmsingle.yaml](https://github.com/Smana/demo-cloud-native-ref/blob/main/observability/base/victoria-metrics-k8s-stack/helmrelease-vmsingle.yaml)

```yaml
apiVersion: helm.toolkit.fluxcd.io/v2
kind: HelmRelease
metadata:
  name: victoria-metrics-k8s-stack
  namespace: observability
spec:
  releaseName: victoria-metrics-k8s-stack
  chart:
    spec:
      chart: victoria-metrics-k8s-stack
      sourceRef:
        kind: HelmRepository
        name: victoria-metrics
        namespace: observability
      version: "0.25.15"
...
  values:
    vmsingle:
      spec:
        retentionPeriod: "1d" # Minimal retention, for tests only
        replicaCount: 1
        storage:
          accessModes:
            - ReadWriteOnce
          resources:
            requests:
              storage: 10Gi
        extraArgs:
          maxLabelsPerTimeseries: "50"
```

Lorsque l'ensemble des manifests Kubernetes sont appliqu√©s, on obtient l'architecture suivante:

<center><img src="vmsingle.png" width=1400 alt=""></center>

* üîí **Acc√®s priv√©**: M√™me si cela ne fait pas vraiment partie des composants li√©s √† la collecte des m√©triques, j'ai souhait√© mettre en avant la fa√ßon dont on acc√®de aux diff√©rentes interfaces. J'ai en effet choisi de capitaliser sur [**Gateway API**](https://gateway-api.sigs.k8s.io/), que j'utilise depuis quelque temps et qui a fait l'objet de [pr√©c√©dents articles](https://blog.ogenki.io/tags/security/). Une alternative serait d'utiliser un composant de VictoriaMetrics, [VMAuth](https://docs.victoriametrics.com/vmauth/?highlight=vmauth), qui peut servir de proxy pour l'autorisation et le routage des acc√®s mais Je n'ai pas retenu cette option pour le moment.


* üë∑ **VMAgent**: Un agent tr√®s l√©ger, dont la fonction principale est de **r√©cup√©rer les m√©triques** et de les acheminer vers une base de donn√©es compatible avec Prometheus.  Par ailleurs, cet agent peut appliquer **des filtres ou des transformations** aux m√©triques avant de les transmettre. En cas d'indisponibilit√© de la destination ou en cas de manque de ressources, il peut mettre en cache les donn√©es sur disque.
VMAgent dispose aussi d'une interface Web permettant de lister les "Targets" (Services qui sont scrap√©s)

<center><img src="vmagent.png" width=800></center>


* üî• **VMAlert** & **VMAlertManager**: Ce sont les composants charg√©s de notifier en cas de probl√®mes, d'anomalies. Je ne vais volontairement pas approfondir le sujet car cela fera l'objet d'un **future acticle**.


* ‚öôÔ∏è **VMsingle**: Il s'agit de la base de donn√©es VictoriaMetrics d√©ploy√©e sous forme d'un pod unique qui prend en charge l'ensemble des op√©rations (lecture, √©criture et persistence des donn√©es).

Lorsque tous les pods sont d√©marr√©s, on peut acc√©der √† l'interface principale de VictoriaMetrics: `VMUI`. Elle permet de visualiser un grand nombre d'informations: √âvidemment nous pourrons parcourir les m√©triques scrap√©es, les requ√™tes les plus utilis√©es, les statistiques relatives √† la cardinalit√© et [bien d'autres](https://docs.victoriametrics.com/#vmui).

<center>
  <video id="VMUI" controls height="800" autoplay loop muted>
    <source src="vmui.webm" type="video/webm">
    Your browser does not support the video tag.
  </video>
</center>

<script>
  var video = document.getElementById('VMUI');
  video.playbackRate = 1.8;
</script>


### La Haute disponibilit√©

Pour ne jamais perdre de vue ce qui se passe sur nos applications, la solution de supervision doit toujours rester op√©rationnelle. Pour cela, tous les composants de VictoriaMetrics peuvent √™tre configur√©s en haute disponibilit√©. En fonction du niveau de redondance souhait√©, plusieurs options s'offrent √† nous.

La plus simple est d'envoyer les donn√©es √† **deux instances** `Single`, les donn√©es sont ainsi dupliqu√©es √† 2 endroits. De plus, on peut envisager de d√©ployer ces instances dans deux r√©gions diff√©rentes.

Il est aussi recommand√© de **redonder les agents** VMAgent qui vont scraper les m√™mes services, afin de s'assurer qu'aucune donn√©e ne soit perdue.

{{% notice note "Bien configurer la De-duplication" %}}
Dans une telle architecture, √©tant donn√© que plusieurs VMAgents envoient des donn√©es et scrappent les m√™mes services, on se retrouve avec des m√©triques en **double**. La [De-duplication](https://docs.victoriametrics.com/#deduplication) dans VictoriaMetrics permet de ne **conserver qu'une seule version** lorsque deux raw samples sont identiques. </br>
Un param√®tre m√©rite une attention particuli√®re : `-dedup.minScrapeInterval`:  Seule la version la **plus r√©cente** sera conserv√©e lorsque raw samples identiques sont trouv√©s dans cet intervale de temps.

Il est aussi recommand√© de :

* Configurer ce param√®tre avec une valeur √©gale au `scrape_interval` que l'on d√©finit dans la configuration Prometheus.
* Garder une valeur de `scrape_interval` identique pour tous les services scrapp√©s.
{{% /notice %}}

Le sch√©ma ci-dessous montre l'une des nombreuses combinaisons possibles pour assurer une disponibilit√© optimale. </br>
‚ö†Ô∏è Cependant, il faut tenir compte du **surco√ªt**, non seulement pour le stockage et le calcul, mais aussi pour les transferts r√©seau entre zones/r√©gions. Il est parfois plus judicieux d'avoir une bonne strat√©gie de **sauvegarde et restauration** üòÖ.

<center><img src="multi-region.png" width=900 alt=""></center>


### Le mode Cluster

Comme mentionn√© plus t√¥t, dans la plupart des cas, le mode `Single` est largement suffisant. Il a l'avantage d'√™tre simple √† maintenir et, avec du scaling vertical, il permet de r√©pondre √† **quasiment tous les cas d'usage**. Il existe aussi un mode Cluster, qui n'est pertinent que dans deux cas pr√©cis :

* Besoin de [multitenant](https://docs.victoriametrics.com/cluster-victoriametrics/#multitenancy). Par exemple pour isoler plusieurs √©quipes ou clients.
* Si les limites du scaling vertical sont atteintes.

Ma configuration permet de choisir entre l'un ou l'autre des modes:

[observability/base/victoria-metrics-k8s-stack/kustomization.yaml](https://github.com/Smana/demo-cloud-native-ref/blob/main/observability/base/victoria-metrics-k8s-stack/kustomization.yaml)

```yaml
resources:
...

  - vm-common-helm-values-configmap.yaml
  # Choose between single or cluster helm release

  # VM Single
  - helmrelease-vmsingle.yaml
  - httproute-vmsingle.yaml

  # VM Cluster
  # - helmrelease-vmcluster.yaml
  # - httproute-vmcluster.yaml
```

<center><img src="vmcluster.png" width=800 alt=""></center>


Dans ce mode, on va **s√©parer les fonctions de lecture, √©criture et de stockage** en 3 services bien distincts.

* ‚úèÔ∏è **VMInsert**: R√©partit les donn√©es sur les instances de VMStorage en utilisant du [consistent hashing](https://en.wikipedia.org/wiki/Consistent_hashing) bas√© sur la time series (combinaison du nom de la m√©trique et de ses labels).

* üíæ **VMStorage**: Est charg√© d'√©crire les donn√©es sur disque et de retourner les donn√©es demand√©es par VMSelect.

* üìñ **VMSelect**: Pour chaque requ√™te va r√©cup√©rer les donn√©es sur les VMStorages.

L'int√©r√™t principal de ce mode est √©videmment de pouvoir adapter le **scaling** en fonction du besoin. Par exemple, si on a besoin de plus de capacit√© en √©criture on va ajouter des replicas VMInsert.

Le param√®tre initial, qui permet d'avoir un niveau de redondance minimum est `replicationFactor` √† `2`. Voici un extrait des _values_ Helm pour le mode cluster.

```yaml
    vmcluster:
      enabled: true
      spec:
        retentionPeriod: "10d"
        replicationFactor: 2
        vmstorage:
          storage:
            volumeClaimTemplate:
              storageClassName: "gp3"
              spec:
                resources:
                  requests:
                    storage: 10Gi
          resources:
            limits:
              cpu: "1"
              memory: 1500Mi
          affinity:
            podAntiAffinity:
              requiredDuringSchedulingIgnoredDuringExecution:
                - labelSelector:
                    matchExpressions:
                      - key: "app.kubernetes.io/name"
                        operator: In
                        values:
                          - "vmstorage"
                  topologyKey: "kubernetes.io/hostname"
          topologySpreadConstraints:
            - labelSelector:
                matchLabels:
                  app.kubernetes.io/name: vmstorage
              maxSkew: 1
              topologyKey: topology.kubernetes.io/zone
              whenUnsatisfiable: ScheduleAnyway
        vmselect:
          storage:
            volumeClaimTemplate:
              storageClassName: "gp3"
```

:information_source: On notera que certains param√®tres font partie des bonnes pratiques Kubernetes, notamment lorsque l'on utilise [Karpenter](https://karpenter.sh/): `topologySpreadConstraints` permet de r√©partir sur diff√©rentes zones, `podAntiAffinity` pour √©viter que 2 pods pour le m√™me service se retrouvent sur le m√™me noeud.

## üõ†Ô∏è La configuration

Ok, c'est cool, VictoriaMetrics est maintenant d√©ploy√© üëè. Il est temps de **configurer** la supervision de nos applications, et pour √ßa, on va s'appuyer sur le pattern op√©rateur de Kubernetes.
Concr√®tement, cela signifie que l'on va d√©clarer des ressources personnalis√©es ([Custom Resources](https://kubernetes.io/docs/concepts/extend-kubernetes/api-extension/custom-resources/)) qui seront interpr√©t√©es par [**VictoriaMetrics Operator**](https://github.com/VictoriaMetrics/operator) pour configurer et g√©rer VictoriaMetrics.

Le Helm chart qu‚Äôon a utilis√© ne d√©ploie pas directement VictoriaMetrics, mais il installe principalement l‚Äôop√©rateur. Cet op√©rateur se charge ensuite de cr√©er et de g√©rer des custom resources comme `VMSingle` ou `VMCluster`, qui d√©terminent comment VictoriaMetrics est d√©ploy√© et configur√© en fonction des besoins.

Le r√¥le de `VMServiceScrape` est de d√©finir **o√π aller chercher les m√©triques** pour un service donn√©. On s‚Äôappuie sur les labels Kubernetes pour identifier le bon service et le bon port.

[observability/base/victoria-metrics-k8s-stack/vmservicecrapes/karpenter.yaml](https://github.com/Smana/cloud-native-ref/blob/main/observability/base/victoria-metrics-k8s-stack/vmservicecrapes/karpenter.yaml)

```yaml
apiVersion: operator.victoriametrics.com/v1beta1
kind: VMServiceScrape
metadata:
  name: karpenter
  namespace: karpenter
spec:
  selector:
    matchLabels:
      app.kubernetes.io/name: karpenter
  endpoints:
    - port: http-metrics
      path: /metrics
  namespaceSelector:
    matchNames:
      - karpenter
```

Nous pouvons v√©rifier que les param√®tres sont bien configur√©s gr√¢ce √† `kubectl`
```console
kubectl get services -n karpenter --selector app.kubernetes.io/name=karpenter -o yaml | grep -A 4 ports
    ports:
    - name: http-metrics
      port: 8000
      protocol: TCP
      targetPort: http-metrics
```

Parfois il n'y pas de service, nous pouvons alors indiquer comment identifier les pods directement avec `VMPodScrape`.

[observability/base/flux-config/observability/vmpodscrape.yaml](https://github.com/Smana/cloud-native-ref/blob/main/observability/base/flux-config/observability/vmpodscrape.yaml)
```yaml
apiVersion: operator.victoriametrics.com/v1beta1
kind: VMPodScrape
metadata:
  name: flux-system
  namespace: flux-system
spec:
  namespaceSelector:
    matchNames:
      - flux-system
  selector:
    matchExpressions:
      - key: app
        operator: In
        values:
          - helm-controller
          - source-controller
          - kustomize-controller
          - notification-controller
          - image-automation-controller
          - image-reflector-controller
  podMetricsEndpoints:
    - targetPort: http-prom
```

Toutes nos applications ne sont pas forc√©ment d√©ploy√©es sur Kubernetes. La ressource `VMScrapeConfig` dans VictoriaMetrics permet d'utiliser plusieurs m√©thodes de "[Service Discovery](https://docs.victoriametrics.com/sd_configs/index.html)". Cette ressource offre la flexibilit√© de d√©finir comment scrapper les cibles via diff√©rents m√©canismes de d√©couverte, tels que les instances EC2 (AWS), les services Cloud ou d'autres syst√®mes. Dans l'exemple ci-dessous, on utilise le tag personnalis√© `observability:node-exporter`, et on applique des transformations de labels. Ce qui nous permet de r√©cup√©rer les m√©triques expos√©es par les [node-exporters](https://github.com/prometheus/node_exporter) install√©s sur ces instances.

[observability/base/victoria-metrics-k8s-stack/vmscrapeconfigs/ec2.yaml](https://github.com/Smana/cloud-native-ref/blob/main/observability/base/victoria-metrics-k8s-stack/vmscrapeconfigs/ec2.yaml)
```yaml
apiVersion: operator.victoriametrics.com/v1beta1
kind: VMScrapeConfig
metadata:
  name: aws-ec2-node-exporter
  namespace: observability
spec:
  ec2SDConfigs:
    - region: ${region}
      port: 9100
      filters:
        - name: tag:observability:node-exporter
          values: ["true"]
  relabelConfigs:
    - action: replace
      source_labels: [__meta_ec2_tag_Name]
      target_label: ec2_name
    - action: replace
      source_labels: [__meta_ec2_tag_app]
      target_label: ec2_application
    - action: replace
      source_labels: [__meta_ec2_availability_zone]
      target_label: ec2_az
    - action: replace
      source_labels: [__meta_ec2_instance_id]
      target_label: ec2_id
    - action: replace
      source_labels: [__meta_ec2_region]
      target_label: ec2_region
```

‚ÑπÔ∏è Si on utilisait d√©j√† le Prometheus Operator, la migration vers VictoriaMetrics est tr√®s simple car il est **compatible** avec les CRDs d√©finies par le Prometheus Operator.

## üìà Visualiser nos m√©triques avec l'op√©rateur Grafana

Il est facile de deviner √† quoi sert le Grafana Operator: Utiliser des ressources Kubernetes pour configurer Grafana üòù. Il permet de cr√©er des d√©ployer des instances Grafana, d'importer des dashboards de diff√©rentes mani√®re (URL, JSON), de les classer dans des r√©pertoires etc...
Il s'agit d'une alternative au fait de tout d√©finir dans le chart Helm et, selon moi, offre une meilleure lecture. Dans cet exemple, je regroupe l'ensemble des ressources relatives √† la supervision de Cilium

```bash
tree  infrastructure/base/cilium/
infrastructure/base/cilium/
‚îú‚îÄ‚îÄ grafana-dashboards.yaml
‚îú‚îÄ‚îÄ grafana-folder.yaml
‚îú‚îÄ‚îÄ httproute-hubble-ui.yaml
‚îú‚îÄ‚îÄ kustomization.yaml
‚îú‚îÄ‚îÄ vmrules.yaml
‚îî‚îÄ‚îÄ vmservicescrapes.yaml
```

La d√©finition du r√©pertoire est super simple

[observability/base/infrastructure/cilium/grafana-folder.yaml](https://github.com/Smana/cloud-native-ref/blob/main/observability/base/infrastructure/cilium/grafana-folder.yaml)
```yaml
apiVersion: grafana.integreatly.org/v1beta1
kind: GrafanaFolder
metadata:
  name: cilium
spec:
  allowCrossNamespaceImport: true
  instanceSelector:
    matchLabels:
      dashboards: "grafana"
```

Puis voici une ressource `Dashboard` qui va chercher la configuration √† partir d'un lien HTTP. Nous pouvons aussi utiliser les dashboards disponibles depuis le [site de Grafana](https://grafana.com/grafana/dashboards/), en indiquant l'ID appropri√© ou carr√©ment mettre la d√©finition au format JSON.

[observability/base/infrastructure/cilium/grafana-dashboards.yaml](https://github.com/Smana/cloud-native-ref/blob/main/observability/base/infrastructure/cilium/grafana-dashboards.yaml)
```yaml
apiVersion: grafana.integreatly.org/v1beta1
kind: GrafanaDashboard
metadata:
  name: cilium-cilium
spec:
  folderRef: "cilium"
  allowCrossNamespaceImport: true
  datasources:
    - inputName: "DS_PROMETHEUS"
      datasourceName: "VictoriaMetrics"
  instanceSelector:
    matchLabels:
      dashboards: "grafana"
  url: "https://raw.githubusercontent.com/cilium/cilium/main/install/kubernetes/cilium/files/cilium-agent/dashboards/cilium-dashboard.json"
```

Notez que j'ai choisi de **ne pas utiliser l'op√©rateur Grafana pour d√©ployer l'instance**, mais de garder celle qui a √©t√© install√©e via le Helm chart de VictoriaMetrics. Il faut donc simplement fournir √† l'op√©rateur Grafana les **param√®tres d'authentification** pour qu'il puisse appliquer les modifications sur cette instance.

[observability/base/grafana-operator/grafana-victoriametrics.yaml](https://github.com/Smana/cloud-native-ref/blob/main/observability/base/grafana-operator/grafana-victoriametrics.yaml)
```yaml
apiVersion: grafana.integreatly.org/v1beta1
kind: Grafana
metadata:
  name: grafana-victoriametrics
  labels:
    dashboards: "grafana"
spec:
  external:
    url: http://victoria-metrics-k8s-stack-grafana
    adminPassword:
      name: victoria-metrics-k8s-stack-grafana-admin
      key: admin-password
    adminUser:
      name: victoria-metrics-k8s-stack-grafana-admin
      key: admin-user
```

Enfin nous pouvons utiliser Grafana et explorer nos diff√©rents dashboards üéâ!

<center>
  <video id="Grafana" controls height="800" autoplay loop muted>
    <source src="grafana.webm" type="video/webm">
    Your browser does not support the video tag.
  </video>
</center>

<script>
  var video = document.getElementById('Grafana');
  video.playbackRate = 1.3;
</script>


## üí≠ Derni√®res remarques

Si l'on se r√©f√®re aux diff√©rents articles consult√©s, l'une des principales raisons pour lesquelles migrer ou choisir VictoriaMetrics serait une **meilleure performance** en r√®gle g√©n√©rale. Cependant il est judicieux de rester prudent car les r√©sultats des benchmarks d√©pendent de plusieurs facteurs, ainsi que de l'objectif recherch√©. C'est pourquoi il est fortement conseill√© de lancer des tests soit m√™me. VictoriaMetrics propose un [jeu de test](https://github.com/VictoriaMetrics/prometheus-benchmark) qui peut √™tre r√©alis√© sur les TSDB compatibles avec Prometheus.

Vous l'aurez compris, aujourd'hui mon choix se porte sur VictoriaMetrics pour la collecte des m√©triques, car j'appr√©cie l'architecture modulaire avec une multitude de combinaisons possibles en fonction de l'**√©volution du besoin**. Cependant, une solution utilisant l'op√©rateur Prometheus fonctionne tr√®s bien dans la plupart des cas et a l'int√©r√™t d'√™tre gouvern√© par une fondation.

Par aileurs, il est important de noter que certaines fonctionnalit√©s ne sont disponibles qu'en [**version Entreprise**](https://docs.victoriametrics.com/enterprise/), notamment le downsampling qui est fort utile lorsque l'on veut garder une grosse quantit√© de donn√©es sur du long terme.

Dans cet article nous avons surtout pu mettre en √©vidence la **facilit√© de mise en oeuvre** pour obtenir une solution qui permette, d'une part de collecter efficacement les m√©triques, et de les visualiser. Ceci, toujours en utilisant le pattern operateur Kubernetes qui permet de faire du GitOps, et de d√©clarer les diff√©rents types de ressources au travers de Custom resources. Ainsi Un d√©veloppeur peut tr√®s bien inclure √† ses manifests, un `VMServiceScrape` et une `VMRule` et, ainsi, inclure la culture de l'observabilit√© dans les processes de livraisons applicative.

Disposer de m√©triques c'est bien bien, mais est-ce suffisant? On va essayer d'y r√©pondre dans les prochains articles ...


## üîñ References

* [Articles sur VictoriaMetrics](https://docs.victoriametrics.com/articles/)
