+++
author = "Smaine Kahlouch"
title = "Appliquer les principes de GitOps √† l'infrastructure: Introduction √† `tf-controller`"
date = "2023-06-01"
summary = "**Weave tf-controller** est un op√©rateur Kubernetes qui permet d'appliquer du code Terraform et apporte certaines fonctionnalit√©s manquantes (r√©conciliation, d√©tection de d√©rive ...). Explorons les principales fonctionnalit√©s üïµÔ∏è"
featureImage = "tf-controller.png"
featured = true
codeMaxLines = 20
usePageBundles = true
toc = true
tags = [
    "data"
]
thumbnail= "weavetf.png"
+++

**Terraform** est probablement l'outil "Infrastructure As Code" le plus utilis√© pour construire, modifier et versionner les changements d'infrastructure Cloud.
Il s'agit d'un projet Open Source d√©velopp√© par Hashicorp et qui utilise le langage [FCL](https://github.com/hashicorp/hcl) pour d√©clarer l'√©tat souhait√© de resources Cloud.
L'√©tat des ressources cr√©√©es est stock√© dans un fichier d'√©tat (terraform state).

On peut consid√©rer que Terraform est un outil "semi-d√©claratif" car il n'y a pas de fonctionnalit√© de **r√©conciliation automatique** int√©gr√©e. Il existe diff√©rentes approches pour r√©pondre √† cette probl√©matique, mais en r√®gle g√©n√©rale, une modification sera appliqu√©e en utilisant `terraform apply`. Le code est bien d√©crit dans des fichiers de configuration HCL (d√©claratif) mais l'ex√©cution est faite de mani√®re imp√©rative.
De ce fait, il peut y avoir de la d√©rive entre l'√©tat d√©clar√© et le r√©el (par exemple, un coll√®gue qui serait pass√© sur la console pour changer un param√®tre üòâ).

‚ùì‚ùì Alors, comment m'assurer que ce qui est commit dans mon repo git est vraiment appliqu√©. Comment √™tre alert√© s'il y a un changement par rapport √† l'√©tat d√©sir√© et comment appliquer automatiquement ce qui est dans mon code (GitOps) ?

C'est la promesse de [**tf-controller**](https://github.com/weaveworks/tf-controller), un operateur Kubernetes opensource de Weaveworks, √©troitement li√© √† Flux (un moteur GitOps de la m√™me soci√©t√©). [**Flux**](https://fluxcd.io/) est l'une des solutions que je pl√©biscite, et je vous invite donc √† lire un [pr√©c√©dent article](https://blog.ogenki.io/post/devflux/).

{{% notice info Info %}}
L'ensemble des √©tapes d√©crites ci-dessous sont faites avec ce [**repo Git**](https://github.com/Smana/demo-tf-controller)
{{% /notice %}}

## :bullseye: Notre objectif

En suivant les √©tapes de cet article nous visons les objectifs suivant:

* D√©ployer un cluster Kubernetes qui servira de "**Control plane**". Pour r√©sumer il h√©bergera le controlleur Terraform qui nous permettra de d√©clarer tous les √©l√©ments d'infrastructure souhait√©s.
* Utiliser **Flux** comme moteur GitOps pour toutes les resources Kubernetes.

Concernant le controleur Terraform, nous allons voir:

* Quelle est le moyen de d√©finir des **d√©pendances** entre modules
* Cr√©ation de **plusieurs resources** AWS: Zone route53, Certificat ACM, r√©seau, cluster EKS.
* Les diff√©rentes options de **reconciliation** (automatique, n√©cessitant une confirmation)
* Comment sauvegarder et **restaurer** un fichier d'√©tat (tfstate)

## üõ†Ô∏è Installer le controleur Terraform

### Le cluster "Control Plane"

Afin de pouvoir utiliser le controleur Kubernetes `tf-controller`, il nous faut d'abord un cluster Kubernetes üòÜ.
Nous allons donc cr√©er un cluster **control plane** en utilisant la ligne de commande `terraform` et les bonnes pratiques EKS.

{{% notice warning Warning %}}
Il est primordial que ce cluster soit r√©siliant, s√©curis√© et supervis√© car il sera responsable de la gestion de l'ensemble des resources AWS cr√©√©es par la suite.
Il est aussi fortement conseill√© d'avoir une politique de sauvegarde du cluster en question, en utilisant par exemple [Velero](https://velero.io/)
{{% /notice %}}

Sans entrer dans le d√©tail, le cluster "control plane" a √©t√© cr√©√© un utilisant [ce code](https://github.com/Smana/demo-tf-controller/tree/main/terraform/controlplane). Cel√†-dit, il est important de noter que toutes les op√©rations de d√©ploiement d'application se font en utilisant Flux.

{{% notice info Info %}}

En suivant les instructions du [README](https://github.com/Smana/demo-tf-controller/blob/main/terraform/controlplane/README.md), un cluster EKS sera cr√©√© mais pas uniquement! </br>
Il faut en effet donner les permissions au controlleur Terraform pour appliquer les changements d'infrastructure.
De plus, Flux doit √™tre install√© et configur√© afin d'appliquer la configuration d√©finie [ici](https://github.com/Smana/demo-tf-controller/tree/main/clusters/controlplane-0).

Au final on se retrouve donc avec plusieurs √©l√©ments install√©s et configur√©s:

* les addons quasi indispensables que sont `aws-loadbalancer-controller` et `external-dns`
* les roles [IRSA](https://docs.aws.amazon.com/eks/latest/userguide/iam-roles-for-service-accounts.html) pour ces m√™mes composants sont install√©s en utilisant `tf-controller`
* La stack de supervision Prometheus / Grafana.
* `sealed-secrets` pour pouvoir stocker les secrets Kubernetes dans le repo Git en toute s√©curit√©.
* Afin de d√©montrer tout cela au bout de quelques minutes l'interface web pour Flux est accessible via l'URL `gitops-<cluster_name>.<domain_name`>

V√©rifier toute de m√™me que le cluster est accessible et que Flux fonctionne correctement

```console
aws eks update-kubeconfig --name controlplane-0 --alias controlplane-0
Updated context controlplane-0 in /home/smana/.kube/config
```

```console
flux check
...
‚úî all checks passed

flux get kustomizations
NAME                    REVISION                SUSPENDED       READY   MESSAGE
flux-config             main@sha1:e2cdaced      False           True    Applied revision: main@sha1:e2cdaced
flux-system             main@sha1:e2cdaced      False           True    Applied revision: main@sha1:e2cdaced
infrastructure          main@sha1:e2cdaced      False           True    Applied revision: main@sha1:e2cdaced
security                main@sha1:e2cdaced      False           True    Applied revision: main@sha1:e2cdaced
tf-controller           main@sha1:e2cdaced      False           True    Applied revision: main@sha1:e2cdaced
...
```

{{% /notice %}}

### Le chart Helm et Flux

Maintenant que notre cluster GitOps est op√©rationnel, nous pouvons constater que **l'ajout le contr√¥leur Terraform** consiste √† utiliser le chart Helm comme sp√©cifi√© dans la [documentation](https://weaveworks.github.io/tf-controller/getting_started/#installation).

Il faut tout d'abord d√©clarer la source:

<span style="color:green">infrastructure/base/tf-controller/source.yaml</span>
```yaml
apiVersion: source.toolkit.fluxcd.io/v1beta2
kind: HelmRepository
metadata:
  name: tf-controller
spec:
  interval: 30m
  url: https://weaveworks.github.io/tf-controller
```

Et d√©finir la HelmRelease:

<span style="color:green">infrastructure/base/tf-controller/release.yaml</span>
```yaml
apiVersion: helm.toolkit.fluxcd.io/v2beta1
kind: HelmRelease
metadata:
  name: tf-controller
spec:
  releaseName: tf-controller
  chart:
    spec:
      chart: tf-controller
      sourceRef:
        kind: HelmRepository
        name: tf-controller
        namespace: flux-system
      version: "0.12.0"
  interval: 10m0s
  install:
    remediation:
      retries: 3
  values:
    resources:
      limits:
        memory: 1Gi
      requests:
        cpu: 200m
        memory: 500Mi
    runner:
      serviceAccount:
        annotations:
          eks.amazonaws.com/role-arn: "arn:aws:iam::${aws_account_id}:role/tfcontroller_${cluster_name}"
```

```console
kubectl get po -n flux-system -l app.kubernetes.io/instance=tf-controller
NAME                             READY   STATUS    RESTARTS   AGE
tf-controller-7ffdc69b54-c2brg   1/1     Running   0          2m6s
```

Dans le repo de demo il y a d√©j√† un certain nombre de ressources AWS d√©clar√©es. Par cons√©quent, au bout de quelques minutes, le cluster fraichement se charge de la cr√©ation de celles-cis:
[![asciicast](https://asciinema.org/a/guDIpkVdD51Cyog9P5NYnuWSq.png)](https://asciinema.org/a/guDIpkVdD51Cyog9P5NYnuWSq?&speed=2)

{{% notice info Info %}}

Bien que la plupart des op√©rations peuvent √™tre effectu√©es de fa√ßon d√©clarative ou en utilisant les outils en ligne de commande `kubectl` et `flux`, il existe aussi un autre outil qui permet d'interragir avec les ressources terraform: [tfctl](https://docs.gitops.weave.works/docs/terraform/tfctl/)

{{% /notice %}}

## üöÄ Appliquer un changement

Parmis les [bonnes pratiques](https://www.terraform-best-practices.com/) avec Terraform, il y a l'usage de **[modules](https://developer.hashicorp.com/terraform/language/modules)**.</br>
Un module est un ensemble de resources Terraform li√©es logigement afin d'obtenir une seule unit√© r√©utilisable. Cela permet d'abstraire la complexit√©, de prendre des entr√©es, effectuer des actions sp√©cifiques et produire des sorties.

Il est possible de cr√©er ses modules et de les mettre √† disposition dans des `Sources` ou d'utiliser les nombreux modules partag√©s et maintenus par les communaut√©s.</br>
Il suffit alors d'indiquer un certains nombre de `variables` afin de l'adapter au contexte.

Avec `tf-controller`, la premi√®re √©tape consiste donc √† indiquer la `Source` du module. Ici nous allons configurer le socle r√©seau sur AWS avec le module [terraform-aws-vpc](https://github.com/terraform-aws-modules/terraform-aws-vpc).

```yaml
apiVersion: source.toolkit.fluxcd.io/v1
kind: GitRepository
metadata:
  name: terraform-aws-vpc
  namespace: flux-system
spec:
  interval: 30s
  ref:
    tag: v5.0.0
  url: https://github.com/terraform-aws-modules/terraform-aws-vpc
```

Nous pouvons ensuite cr√©er la resource `Terraform` qui en fait usage.</br>
Les principaux param√®tres qui permettent de contr√¥ler la fa√ßon dont sont appliqu√©es les modifications sont `.spec.approvePlan` et `.spec.autoApprove`

### üö® D√©tection de la d√©rive

D√©finir `spec.approvePlan` avec une valeur √† `disable` permet uniquement de notifier que l'√©tat actuel des ressources a d√©riv√© par rapport au code Terraform.
Cela permet notamment de choisir le moment et la mani√®re dont l'application des changements sera faite.

### üîß Application manuelle


```yaml
apiVersion: infra.contrib.fluxcd.io/v1alpha2
kind: Terraform
metadata:
  name: vpc-dev
spec:
  interval: 8m
  path: .
  destroyResourcesOnDeletion: true # You wouldn't do that on a prod env ;)
  approvePlan: "plan-v5.0.0@sha1:26c38a66f1"
  sourceRef:
    kind: GitRepository
    name: terraform-aws-vpc
    namespace: flux-system
  storeReadablePlan: human
  vars:
    - name: name
      value: vpc-dev
    - name: cidr
      value: "10.42.0.0/16"
    - name: azs
      value:
        - "eu-west-3a"
        - "eu-west-3b"
        - "eu-west-3c"
    - name: private_subnets
      value:
        - "10.42.0.0/19"
        - "10.42.32.0/19"
        - "10.42.64.0/19"
    - name: public_subnets
      value:
        - "10.42.96.0/24"
        - "10.42.97.0/24"
        - "10.42.98.0/24"
    - name: enable_nat_gateway
      value: true
    - name: single_nat_gateway
      value: true
    - name: private_subnet_tags
      value:
        "kubernetes.io/role/elb": 1
        "karpenter.sh/discovery": dev
    - name: public_subnet_tags
      value:
        "kubernetes.io/role/elb": 1
  writeOutputsToSecret:
    name: vpc-dev
```

### ü§ñ Application automatique


### üîÑ Entr√©es et sorties: d√©pendances entre modules


## üíæ Sauvegarder et restaurer un tfstate

Dans mon cas je souhaite ne pas avoir a recr√©er la zone et le certificat √† chaque destruction du controlplane. Voici un exemple des √©tapes √† mener pour que je puisse **restaurer** l'√©tat de ces resources lorsque j'utilise cette demo.
(Il s'agit d'une proc√©dure manuelle, on pr√©ferera une solution de sauvegarde du cluster pour du la production.)


```console
tfctl show plan route53-cloud-hostedzone

Terraform used the selected providers to generate the following execution
plan. Resource actions are indicated with the following symbols:
  + create

Terraform will perform the following actions:

  # aws_route53_zone.this will be created
  + resource "aws_route53_zone" "this" {
      + arn                 = (known after apply)
      + comment             = "Experimentations for blog.ogenki.io"
      + force_destroy       = false
      + id                  = (known after apply)
      + name                = "cloud.ogenki.io"
      + name_servers        = (known after apply)
      + primary_name_server = (known after apply)
      + tags                = {
          + "Name" = "cloud.ogenki.io"
        }
      + tags_all            = {
          + "Name" = "cloud.ogenki.io"
        }
      + zone_id             = (known after apply)
    }

Plan: 1 to add, 0 to change, 0 to destroy.

Changes to Outputs:
  + domain_name = "cloud.ogenki.io"
  + nameservers = (known after apply)
  + zone_arn    = (known after apply)
  + zone_id     = (known after apply)

Plan generated: set approvePlan: "plan-main@sha1:345394fb4a82b9b258014332ddd556dde87f73ab" to approve this plan.
To set the field, you can also run:

  tfctl approve route53-cloud-hostedzone -f filename.yaml
```


Exporter le tfstate pr√©sent dans le secret Kubernetes:

```console
WORKSPACE="default"
STACK="route53-cloud-hostedzone"
BACKUPDIR="${HOME}/tf-controller-backup"

mkdir -p ${BACKUPDIR}

kubectl get secrets -n flux-system tfstate-${WORKSPACE}-${STACK} -o jsonpath='{.data.tfstate}' | \
base64 -d | gzip -d > ${BACKUPDIR}/${WORKSPACE}-${STACK}.tfstate
```

```bash
gzip ${BACKUPDIR}/${WORKSPACE}-${STACK}.tfstate

cat <<EOF | kubectl apply -f -
apiVersion: v1
kind: Secret
metadata:
  name: tfstate-${WORKSPACE}-${STACK}
  namespace: flux-system
  annotations:
    encoding: gzip
type: Opaque
data:
  tfstate: $(cat ${BACKUPDIR}/${WORKSPACE}-${STACK}.tfstate.gz | base64 -w 0)
EOF
```

```console
tfctl get
NAMESPACE       NAME                            READY   MESSAGE                                                                                                                 PLAN PENDING    AGE
...
flux-system     route53-cloud-hostedzone        Unknown Plan generated: set approvePlan: "plan-main@sha1:345394fb4a82b9b258014332ddd556dde87f73ab" to approve this plan.        true            16 minutes
```

```console
tfctl replan acm-cloud --request-timeout 0
Ôò´ Replan requested for flux-system/acm-cloud
Error: timed out waiting for the condition
```

```console
tfctl get
NAMESPACE       NAME                            READY   MESSAGE                                                                                                                 PLAN PENDING    AGE
flux-system     route53-cloud-hostedzone        True    Outputs written: main@sha1:d0934f979d832feb870a8741ec01a927e9ee6644                                                     false           19 minutes
```

## :detective: Troubleshooting

break glass
break-glass tfctl

## üîç Focus sur certaines fonctionnalit√©s de Flux

Oui j'ai un peu menti sur l'agenda üòù. Il me semblait n√©cessaire de mettre en lumi√®re 2 fonctionnalit√©s que je n'avais pas exploit√© jusque l√† et qui sont fort utiles!

### Substition de variables

Lorsque Flux est initilias√© un certain nombre de `Kustomization` sp√©cifique √† ce cluster sont cr√©es.
Il est possible d'y indiquer des **variables de substitution** qui pourront √™tre utilis√©s dans l'ensemble des ressources d√©ploy√©es par cette `Kustomization`. **Cela permet d'√©viter un maximum la d√©duplication de code**.

J'ai d√©couvert l'efficacit√© de cette fonctionnalit√© tr√®s r√©cemment. Je vais d√©crire ici la fa√ßon dont je l'utilise:

Le code terraform qui cr√©e un cluster EKS, g√©n√®re aussi une `ConfigMap` qui contient les **variables propres au cluster**.
On y retrouvera bien s√ªr le nom du cluster, mais aussi tous les param√®tres qui varient entre les clusters et qui sont utilis√©s dans les manifests Kubernetes.

<span style="color:green">terraform/controlplane/flux.tf</span>

```hcl
resource "kubernetes_config_map" "flux_clusters_vars" {
  metadata {
    name      = "eks-${var.cluster_name}-vars"
    namespace = "flux-system"
  }

  data = {
    cluster_name      = var.cluster_name
    oidc_provider_arn = module.eks.oidc_provider_arn
    aws_account_id    = data.aws_caller_identity.this.account_id
    region            = var.region
    environment       = var.env
    vpc_id            = module.vpc.vpc_id
  }
  depends_on = [flux_bootstrap_git.this]
}
```

Comme sp√©cifi√© pr√©cedemment, les variables de substition sont d√©finies dans les `Kustomization`. Prenons un exemple concret.
Ci-dessous on d√©finie la Kustomization qui d√©ploie les r√¥les IRSA pour le cluster `controlplane-0`. </br>
On consomme ici la `ConfigMap` cr√©e √† la cr√©ation du cluster EKS.

<span style="color:green">clusters/controlplane-0/infrastructure.yaml</span>

```yaml
apiVersion: kustomize.toolkit.fluxcd.io/v1
kind: Kustomization
metadata:
  name: tf-custom-resources
  namespace: flux-system
spec:
  prune: true
  interval: 4m0s
  path: ./infrastructure/controlplane-0/terraform/custom-resources
  postBuild:
    substitute:
      domain_name: "cloud.ogenki.io"
    substituteFrom:
      - kind: ConfigMap
        name: eks-controlplane-0-vars
      - kind: Secret
        name: eks-controlplane-0-vars
        optional: true
  sourceRef:
    kind: GitRepository
    name: flux-system
  dependsOn:
    - name: tf-controller
```

Et donc voici un exemple de resource Kubernetes qui en fait usage. **Cet unique manifest peut √™tre utilis√© par tous les clusters!**.

<span style="color:green">infrastructure/base/external-dns/helmrelease.yaml</span>

```yaml
apiVersion: helm.toolkit.fluxcd.io/v2beta1
kind: HelmRelease
metadata:
  name: external-dns
spec:
...
  values:
    global:
      imageRegistry: public.ecr.aws
    fullnameOverride: external-dns
    aws:
      region: ${region}
      zoneType: "public"
      batchChangeSize: 1000
    domainFilters: ["${domain_name}"]
    logFormat: json
    txtOwnerId: "${cluster_name}"
    serviceAccount:
      annotations:
        eks.amazonaws.com/role-arn: "arn:aws:iam::${aws_account_id}:role/${cluster_name}-external-dns"

```

### Web UI (Weave GitOps)

Dans mon [pr√©c√©dent article sur Flux](https://blog.ogenki.io/post/devflux/), je mentionnais le fait que l'un des inconv√©nients (si l'on compare avec son principale concurrent: ArgoCD) est le manque d'une interface Web. Bien que je sois un adepte de la ligne de commande, c'est parfois bien utile d'avoir une vue synth√©tique et de pouvoir effectuer certaines op√©ration en quelques clicks :computer_mouse:

C'est d√©sormais possible avec [Weave Gitops](https://github.com/weaveworks/weave-gitops)! Bien entendu ce n'est pas comparable avec l'UI d'ArgoCD, mais l'essentiel est l√†: Mettre en pause la r√©concilation, visualiser les manifests, les d√©pendances, les √©v√©nements...

![Weave-Gitops](weave-gitops.gif)

Il existe aussi le [plugin VSCode](https://github.com/weaveworks/vscode-gitops-tools) comme alternative.

## üí≠ Derni√®re remarques

{{% notice note Note %}}

ne pas donner les droits Administrator.
ne pas donner acc√®s au cluster.
Volontairement pousser loin l'exercice mais il faut une approche prudente. Drift detection, resources simples et limit√© √† un petit nombre, application automatique uniquement de resources qui n'ont pas un impact critique sur la prod.

{{% /notice %}}

Limitations module existant outputs maps, diff√©rents type d'inputs, informations sensibles affich√©es en clair dans le statut de la resource.
